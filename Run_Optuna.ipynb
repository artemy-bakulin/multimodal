{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cba3b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/artemy/multimodal_proj/nb/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "#import time\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "#from tqdm import tqdm\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "import utils\n",
    "\n",
    "from importlib import reload\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f1efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_n = 0\n",
    "device = torch.device(f\"cuda:{cuda_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85222b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Universal_Model(utils.CustomModel):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int,\n",
    "                 layers_sizes = [512] * 4,\n",
    "                 concat_pos = 4,\n",
    "                 n_of_layers_to_concat = 3,\n",
    "                 dropout = 1,\n",
    "                 device = 'cpu',\n",
    "                 **kwargs \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.layers_sizes = [self.input_dim] + self.layers_sizes + [self.output_dim]\n",
    "        self.n_layers = len(self.layers_sizes) - 1\n",
    "        modules = []\n",
    "        for i in range(self.n_layers):\n",
    "            if i != self.concat_pos:\n",
    "                input_dim = self.layers_sizes[i]\n",
    "            else:\n",
    "                input_dim = sum(self.layers_sizes[self.concat_pos-self.n_of_layers_to_concat+1:self.concat_pos+1])\n",
    "            output_dim = self.layers_sizes[i + 1]\n",
    "            if i < self.n_layers and dropout != 1:\n",
    "                modules.append(nn.Dropout1d(dropout))\n",
    "            modules.append(nn.Linear(input_dim, output_dim))\n",
    "            if i < self.n_layers - 1:\n",
    "                modules.append(nn.BatchNorm1d(num_features=output_dim))          \n",
    "                modules.append(nn.SiLU())\n",
    "        self.net = nn.Sequential(*modules)\n",
    "        self.net.apply(utils.init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fc_layer_n = 0\n",
    "        layer_outputs = []\n",
    "        for module in self.net:\n",
    "            if fc_layer_n == self.concat_pos and isinstance(module, nn.Linear):\n",
    "                x = torch.concat(layer_outputs[-self.n_of_layers_to_concat:], 1)\n",
    "            x = module(x)\n",
    "            if isinstance(module, nn.SiLU):\n",
    "                layer_outputs.append(x)\n",
    "            if isinstance(module, nn.Linear):\n",
    "                fc_layer_n += 1\n",
    "        return x\n",
    " \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0d02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/artemy/multimodal_proj/data/tuning_data/'\n",
    "\n",
    "\n",
    "def configure_data_loaders(data_dir,\n",
    "                           train=True,\n",
    "                           n_of_PCs=48,\n",
    "                           cite=True,\n",
    "                           cd=False,\n",
    "                           cycle=False,\n",
    "                           imputed=False,\n",
    "                           batch_size=2048):\n",
    "    inputs_file = data_dir\n",
    "    targets_file = data_dir\n",
    "    cycle_levels = ''\n",
    "    cd_levels = ''\n",
    "    if cite: \n",
    "        inputs_file += 'cite_gex_'\n",
    "        targets_file += 'cite_adt_'\n",
    "    else:\n",
    "        inputs_file += 'atac_'\n",
    "        targets_file += 'gex_'\n",
    "    if train:\n",
    "        inputs_file += 'train'\n",
    "        targets_file += 'train'\n",
    "    else:\n",
    "        inputs_file += 'test'\n",
    "        targets_file += 'train'\n",
    "    if imputed:\n",
    "        rna_file = inputs_file + '_imputed'\n",
    "    else:\n",
    "        rna_file = inputs_file\n",
    "    if cd:\n",
    "        cd_file = rna_file + '_cd.sparse.npz'\n",
    "    if cycle:\n",
    "        cycle_file = rna_file + '_cycle.sparse.npz'\n",
    "    inputs_file += '_svd' + '.sparse.npz'\n",
    "    targets_file += '.sparse.npz'\n",
    "    \n",
    "    inputs = utils.load_sparse_data(inputs_file)\n",
    "    targets = utils.load_sparse_data(targets_file)\n",
    "    \n",
    "    inputs = inputs[:, :n_of_PCs]\n",
    "    \n",
    "    if cd:\n",
    "        cd_inputs = utils.load_sparse_data(cd_file)\n",
    "        inputs = np.concatenate((inputs, cd_inputs), 1)\n",
    "        \n",
    "    if cycle:\n",
    "        cycle_inputs = utils.load_sparse_data(cycle_file)\n",
    "        inputs = np.concatenate((inputs, cycle_inputs), 1)\n",
    "    \n",
    "    if train:\n",
    "        train_loader, val_loader = utils.make_loaders(inputs, targets, val_size=2048 * 2, batch_size=batch_size, num_workers=1)\n",
    "        return train_loader, val_loader\n",
    "    else:\n",
    "        test_loader = utils.make_loaders(inputs, batch_size=batch_size, num_workers=1)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153ea9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_params, trainer_params, train_loader, val_loader):\n",
    "    trainer = utils.Trainer(**trainer_params)\n",
    "    trainer.add_train_loader(train_loader)\n",
    "    trainer.add_val_loader(val_loader)\n",
    "    trainer.add_model(model, model_params)\n",
    "    val_loss = trainer.fit(return_val_loss=True, verbose=False)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae95fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial, model, device, data_dir, cite=True):\n",
    "    \n",
    "    model_params = {}\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 25)\n",
    "    model_params['layers_sizes'] = []\n",
    "    for layer in range(num_layers):\n",
    "        ls = trial.suggest_int(f\"ls_{layer}\", 10, 10000)\n",
    "        model_params['layers_sizes'].append(ls)\n",
    "    \n",
    "    model_params['concat_pos'] = trial.suggest_int(\"concat_pos\", 1, num_layers)\n",
    "    max_concat_pos = min(1, model_params['concat_pos']-1)\n",
    "    model_params['n_of_layers_to_concat'] = trial.suggest_int(\"n_of_layers_to_concat\", 1, max_concat_pos)\n",
    "    \n",
    "    model_params['dropout'] = trial.suggest_float(\"dropout\", 1e-2, 1)\n",
    "    \n",
    "    \n",
    "    trainer_params = {}\n",
    "    trainer_params['device'] = device\n",
    "    \n",
    "    trainer_params[\"wd\"] = trial.suggest_float(\"wd\", 1e-7, 1e1, log=True)\n",
    "    trainer_params[\"lr\"] = trial.suggest_float(\"lr\", 1e-5, 1e1, log=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    trainer_params['max_epochs'] = trial.suggest_int(\"max_epochs\", 1, 20)\n",
    "    trainer_params['max_schedule_epoch'] = trial.suggest_int(\"max_schedule_epoch\", 1, trainer_params['max_epochs'])\n",
    "    if trainer_params['max_epochs'] != trainer_params['max_schedule_epoch']:\n",
    "        trainer_params['min_lr'] = trial.suggest_float(\"min_lr\", 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    trainer_params['sparsity_beta'] = trial.suggest_float(\"sparsity_beta\", 1e-9, 10, log=True)\n",
    "    trainer_params['sparsity_rho'] = trial.suggest_float('sparsity_rho', 1e-5, 0.05, log=True)\n",
    "\n",
    "    # regularization\n",
    "    trainer_params['l1_weight'] = trial.suggest_float('l1_weight', 1e-6, 1, log=True)\n",
    "    trainer_params['l2_weight'] = trial.suggest_float('l2_weight', 1e-6, 1, log=True)\n",
    "    \n",
    "    trainer_params['use_swa'] = trial.suggest_categorical('use_swa', [True, False])\n",
    "    if trainer_params['use_swa']:\n",
    "        trainer_params['swa_start'] = trial.suggest_int(\"swa_start\", 1, trainer_params['max_epochs'])\n",
    "        if trainer_params['use_swa']:\n",
    "            model = AveragedModel(model)\n",
    "    \n",
    "    if not trainer_params['use_swa']:\n",
    "        trainer_params['use_one_cycle'] = trial.suggest_categorical('use_one_cycle', [True, False])\n",
    "        \n",
    "    \n",
    "    n_of_PCs = trial.suggest_int(\"n_of_PCs\", 5, 512)\n",
    "    if cite:\n",
    "        cd = trial.suggest_categorical('cd', [True, False])\n",
    "        cycle = trial.suggest_categorical('cycle', [True, False])\n",
    "        imputed = trial.suggest_categorical('imputed', [True, False])\n",
    "    \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [512, 1024, 2048, 4096])\n",
    "    \n",
    "    train_loader, val_loader = configure_data_loaders(data_dir,\n",
    "                                                       train=True,\n",
    "                                                       n_of_PCs=n_of_PCs,\n",
    "                                                       cite=cite,\n",
    "                                                       cd=cd,\n",
    "                                                       cycle=cycle,\n",
    "                                                       imputed=imputed,\n",
    "                                                       batch_size=batch_size)\n",
    "    \n",
    "    val_loss = run_model(model, model_params, trainer_params, train_loader, val_loader)\n",
    "    \n",
    "    return val_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-25 20:16:47,604]\u001b[0m A new study created in memory with name: no-name-7ff88621-1f51-4559-8fa8-737af8a0e978\u001b[0m\n",
      "  6%|█████▉                                                                                              | 1/17 [00:18<04:59, 18.71s/it]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "initialized_objective = lambda x: objective(x, model=Universal_Model, device=device, data_dir=data_dir, cite=True)\n",
    "study.optimize(initialized_objective, n_trials=1000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6613845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014eec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
